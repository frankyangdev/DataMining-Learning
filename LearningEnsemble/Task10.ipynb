{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\r\n",
        "from sklearn.datasets import make_friedman1\r\n",
        "from sklearn.ensemble import GradientBoostingRegressor\r\n",
        "\r\n",
        "'''\r\n",
        "GradientBoostingRegressor参数解释：\r\n",
        "loss：{‘ls’, ‘lad’, ‘huber’, ‘quantile’}, default=’ls’：‘ls’ 指最小二乘回归. ‘lad’ (最小绝对偏差) 是仅基于输入变量的顺序信息的高度鲁棒的损失函数。. ‘huber’ 是两者的结合. ‘quantile’允许分位数回归（用于alpha指定分位数）\r\n",
        "learning_rate：学习率缩小了每棵树的贡献learning_rate。在learning_rate和n_estimators之间需要权衡。\r\n",
        "n_estimators：要执行的提升次数。\r\n",
        "subsample：用于拟合各个基础学习者的样本比例。如果小于1.0，则将导致随机梯度增强。subsample与参数n_estimators。选择会导致方差减少和偏差增加。subsample < 1.0\r\n",
        "criterion：{'friedman_mse'，'mse'，'mae'}，默认='friedman_mse'：“ mse”是均方误差，“ mae”是平均绝对误差。默认值“ friedman_mse”通常是最好的，因为在某些情况下它可以提供更好的近似值。\r\n",
        "min_samples_split：拆分内部节点所需的最少样本数\r\n",
        "min_samples_leaf：在叶节点处需要的最小样本数。\r\n",
        "min_weight_fraction_leaf：在所有叶节点处（所有输入样本）的权重总和中的最小加权分数。如果未提供sample_weight，则样本的权重相等。\r\n",
        "max_depth：各个回归模型的最大深度。最大深度限制了树中节点的数量。调整此参数以获得最佳性能；最佳值取决于输入变量的相互作用。\r\n",
        "min_impurity_decrease：如果节点分裂会导致杂质的减少大于或等于该值，则该节点将被分裂。\r\n",
        "min_impurity_split：提前停止树木生长的阈值。如果节点的杂质高于阈值，则该节点将分裂\r\n",
        "max_features{‘auto’, ‘sqrt’, ‘log2’}，int或float：寻找最佳分割时要考虑的功能数量：\r\n",
        "\r\n",
        "如果为int，则max_features在每个分割处考虑特征。\r\n",
        "\r\n",
        "如果为float，max_features则为小数，并 在每次拆分时考虑要素。int(max_features * n_features)\r\n",
        "\r\n",
        "如果“auto”，则max_features=n_features。\r\n",
        "\r\n",
        "如果是“ sqrt”，则max_features=sqrt(n_features)。\r\n",
        "\r\n",
        "如果为“ log2”，则为max_features=log2(n_features)。\r\n",
        "\r\n",
        "如果没有，则max_features=n_features。\r\n",
        "'''\r\n",
        "\r\n",
        "X, y = make_friedman1(n_samples=1200, random_state=0, noise=1.0)\r\n",
        "X_train, X_test = X[:200], X[200:]\r\n",
        "y_train, y_test = y[:200], y[200:]\r\n",
        "est = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1,\r\n",
        "    max_depth=1, random_state=0, loss='ls').fit(X_train, y_train)\r\n",
        "mean_squared_error(y_test, est.predict(X_test))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_regression\r\n",
        "from sklearn.ensemble import GradientBoostingRegressor\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "X, y = make_regression(random_state=0)\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(\r\n",
        "    X, y, random_state=0)\r\n",
        "reg = GradientBoostingRegressor(random_state=0)\r\n",
        "reg.fit(X_train, y_train)\r\n",
        "reg.score(X_test, y_test)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}