{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**写在前面**：本节内容是 [Datawhale三月的组队学习 - 集成学习（上）- CH2-机器学习基础模型回顾 -【Task4 掌握回归模型的评估及超参数调优】](https://github.com/datawhalechina/team-learning-data-mining/blob/master/EnsembleLearning/CH2-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E6%A8%A1%E5%9E%8B%E5%9B%9E%E9%A1%BE/%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80.ipynb) 的学习笔记，对应notebook的  节，学习周期天（后调整为2天）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入库和数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T15:04:23.295252Z",
     "start_time": "2021-03-24T15:04:23.288308Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVR # 由前面的测试可以发现，默认参数的SVR的回归效果最差，这里通过学习对其进行超参数调参\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection  import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.preprocessing import StandardScaler # 标准化\n",
    "from sklearn.pipeline import Pipeline\n",
    "# Day1\n",
    "from sklearn.model_selection import GridSearchCV # 网格搜索\n",
    "from sklearn.model_selection import RandomizedSearchCV # 随机搜索\n",
    "from scipy.stats import uniform  # 引入均匀分布设置参数\n",
    "# Day2\n",
    "from bayes_opt import BayesianOptimization # 贝叶斯优化\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import sko # 集成了几个启发式算法的包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T13:36:29.183704Z",
     "start_time": "2021-03-24T13:36:29.167747Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "# boston数据集作为本笔记的实验数据\n",
    "boston = datasets.load_boston()\n",
    "X = boston.data\n",
    "y = boston.target\n",
    "features = boston.feature_names\n",
    "boston_data = pd.DataFrame(X,columns=features)\n",
    "boston_data[\"Price\"] = y\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.25) # 数据切分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T13:40:13.205406Z",
     "start_time": "2021-03-24T13:40:13.178439Z"
    },
    "init_cell": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 30.161150722632946\n"
     ]
    }
   ],
   "source": [
    "# 使用未调参的SVR作为调参实验模型\n",
    "pipe_svr = Pipeline([(\"StandardScaler\",StandardScaler()), (\"svr\",SVR())])\n",
    "pipe_svr.fit(X_train, y_train)\n",
    "y_pred = pipe_svr.predict(X_test)\n",
    "print('MSE:',MSE(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 基础概念\n",
    "**参考资料**：\n",
    "- [《机器学习模型的超参数优化》- DeepHub公众号翻译](https://baijiahao.baidu.com/s?id=1665683313439416501&wfr=spider&for=pc)\n",
    "- [4种主流超参数调优技术](https://zhuanlan.zhihu.com/p/234509605)\n",
    "- [贝叶斯优化 Bayesian Optimization](https://blog.csdn.net/qq_40597317/article/details/80888837)\n",
    "- [模型参数优化（一）：遗传算法](https://blog.csdn.net/qq_27586341/article/details/93622507)\n",
    "- [模型参数优化（二）：粒子群优化](https://blog.csdn.net/qq_27586341/article/details/93634155)\n",
    "- [模型参数优化（三）：模拟退火](https://blog.csdn.net/qq_27586341/article/details/93634978)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 超参数\n",
    "超参数是在开始学习过程之前设置值的参数，其值无法从数据中估计。相反，其他参数的值通过训练得出。\n",
    "  - 超参数通常用于帮助估计模型参数。\n",
    "  - 超参数通常由人工指定。\n",
    "  - 超参数通常可以使用启发式设置。\n",
    "  - 超参数经常被调整为给定的预测建模问题。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 调优方法简要介绍\n",
    "1. **网格搜索 GridSearch**  \n",
    "    搜索的思想非常简单，假设有2个超参数需要去选择，就把所有的超参数选择列出来分别做排列组合。假设有:\n",
    "    $$\\lambda = {0.01, 0.1, 1.0}$$\n",
    "    $$\\alpha = {0.01, 0.1, 1.0}$$\n",
    "    可以以此做一个排列组合，然后针对每组超参数分别建立一个模型，然后选择测试误差最小的那组超参数。  \n",
    "    换句话说，我们需要从超参数空间中寻找最优的超参数，很像一个网格中找到一个最优的节点，因此叫`网格搜索`。\n",
    "    - 【优点】：可以找到期望中的最优组合。\n",
    "    - 【缺点】：需要搜索的空间太大，费时费资源。尤其是组合情况呈指数级增长，使得很多情况下无法使用。\n",
    "2. **随机搜索 RandomizedSearch**\n",
    "    随机搜索中的每个参数都是从可能的参数值的分布中进行采样。\n",
    "    - 【优点】：可以独立于参数数量和可能的值来选择计算成本;添加不影响性能的参数不会降低效率。\n",
    "    - 【缺点】：可能找不到最优的组合\n",
    "3. **基于梯度的优化方法**  \n",
    "    通常用于神经网络内，应用场景并不广泛。主要限制有：\n",
    "    - 超参数优化通常不是一个平滑的过程\n",
    "    - 超参数优化往往具有非凸的性质\n",
    "4. **贝叶斯优化**\n",
    "    - 【优点】：既不需要求导，也不要求凸函数；只需要不断取样，来推测函数的最大值，且采样的点也不多\n",
    "    - 【缺点】：容易陷入局部最优；资源消耗大；高维灾难\n",
    "5. **遗传算法**\n",
    "6. **粒子群优化**\n",
    "7. **模拟退火**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 调优方法\n",
    "**参考资料**：\n",
    "- [sklearn-model_evaluation-scoring parameter](https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sklearn里的网格搜索\n",
    "**sklearn参数**:\n",
    "- `param_grid`:传入一个字典，形如：{'参数名':[参数序列]}。\n",
    "- `scoring`:用于评分的策略。支持输入：\n",
    "    - 单个策略：\n",
    "        - 字符串的形式，具体名称可参阅[评分参数](https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter)\n",
    "        - a callable that returns a single value.(可调用对象，应该是函数这些)\n",
    "    - 多个策略：\n",
    "        - 唯一字符串的列表或元组\n",
    "        - 可调用的返回字典，其中的键是度量标准名称，值是度量标准分数\n",
    "        - 以度量名称作为键并可调用a值的字典。\n",
    "- `cv`:K折交叉检验的折数  \n",
    "**注**:参数未全部列出，详细可见参考文档"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T14:15:49.713088Z",
     "start_time": "2021-03-24T14:15:46.740001Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最优得分:  16.18467140142489\n",
      "最优组合:  {'svr__C': 10.0, 'svr__gamma': 0.1, 'svr__kernel': 'rbf'}\n",
      "组合个数:  32\n"
     ]
    }
   ],
   "source": [
    "pipe_svr = Pipeline([(\"StandardScaler\",StandardScaler()), (\"svr\",SVR())])\n",
    "param_range = [0.01, 0.1, 1.0, 10.0]\n",
    "param_grid = {\"svr__C\":param_range, \n",
    "              \"svr__gamma\":param_range, \n",
    "              \"svr__kernel\":[\"linear\",\"rbf\"]}\n",
    "gs = GridSearchCV(pipe_svr, \n",
    "                  param_grid, \n",
    "                  scoring = 'neg_mean_squared_error', \n",
    "                  cv = 10)\n",
    "gs.fit(X_train, y_train)\n",
    "print(\"最优得分: \", -gs.best_score_) # 这里因为要寻找最大化目标，所以对均方误差进行取反\n",
    "print(\"最优组合: \", gs.best_params_)\n",
    "print(\"组合个数: \", len(gs.cv_results_['params']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sklearn里的随机搜索\n",
    "**sklearn参数**: 和网格搜索相一致，这里不再说明。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T14:15:03.894184Z",
     "start_time": "2021-03-24T14:15:00.107045Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最优得分:  26.28265445223402\n",
      "最优组合:  {'svr__C': 9.004510129566087, 'svr__gamma': 9.472441206770952, 'svr__kernel': 'linear'}\n",
      "组合个数:  32\n"
     ]
    }
   ],
   "source": [
    "pipe_svr = Pipeline([(\"StandardScaler\",StandardScaler()), (\"svr\",SVR())])\n",
    "param_range = uniform(loc=0, scale=10)\n",
    "param_grid = {\"svr__C\":param_range, \n",
    "              \"svr__gamma\":param_range, \n",
    "              \"svr__kernel\":[\"linear\",\"rbf\"]}\n",
    "rs = RandomizedSearchCV(pipe_svr, \n",
    "                        param_grid, \n",
    "                        scoring = 'neg_mean_squared_error', \n",
    "                        cv = 10,\n",
    "                        n_iter=32 # 搜索次数与网格搜索保持一致)\n",
    "rs.fit(X_train, y_train)\n",
    "print(\"最优得分: \", -rs.best_score_) # 这里因为要寻找最大化目标，所以对均方误差进行取反\n",
    "print(\"最优组合: \", rs.best_params_)\n",
    "print(\"组合个数: \", len(rs.cv_results_['params']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 课程外的优化算法\n",
    "**参考资料**:\n",
    "- [调参神器贝叶斯优化（bayesian-optimization）实战篇](https://www.jianshu.com/p/92d8943fb0ba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 贝叶斯优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T15:00:20.992185Z",
     "start_time": "2021-03-24T15:00:13.606199Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |     C     |   gamma   |\n",
      "-------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-92.43   \u001b[0m | \u001b[0m 4.868   \u001b[0m | \u001b[0m 5.639   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m-92.69   \u001b[0m | \u001b[0m 5.433   \u001b[0m | \u001b[0m 9.723   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-92.82   \u001b[0m | \u001b[0m 6.015   \u001b[0m | \u001b[0m 5.96    \u001b[0m |\n",
      "| \u001b[95m 4       \u001b[0m | \u001b[95m-91.96   \u001b[0m | \u001b[95m 4.113   \u001b[0m | \u001b[95m 4.807   \u001b[0m |\n",
      "| \u001b[95m 5       \u001b[0m | \u001b[95m-91.56   \u001b[0m | \u001b[95m 2.9     \u001b[0m | \u001b[95m 8.001   \u001b[0m |\n",
      "| \u001b[95m 6       \u001b[0m | \u001b[95m-91.43   \u001b[0m | \u001b[95m 2.262   \u001b[0m | \u001b[95m 6.724   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-92.46   \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 8.552   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-91.63   \u001b[0m | \u001b[0m 1.508   \u001b[0m | \u001b[0m 4.585   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-91.43   \u001b[0m | \u001b[0m 2.37    \u001b[0m | \u001b[0m 1.455   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-92.5    \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.1     \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-92.12   \u001b[0m | \u001b[0m 4.398   \u001b[0m | \u001b[0m 1.115   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-91.45   \u001b[0m | \u001b[0m 2.473   \u001b[0m | \u001b[0m 2.934   \u001b[0m |\n",
      "| \u001b[95m 13      \u001b[0m | \u001b[95m-89.89   \u001b[0m | \u001b[95m 10.0    \u001b[0m | \u001b[95m 0.1     \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-92.64   \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 1.642   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-89.93   \u001b[0m | \u001b[0m 9.649   \u001b[0m | \u001b[0m 0.1     \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-90.1    \u001b[0m | \u001b[0m 8.531   \u001b[0m | \u001b[0m 0.1     \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-90.55   \u001b[0m | \u001b[0m 7.068   \u001b[0m | \u001b[0m 0.1     \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-92.64   \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 10.0    \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-92.85   \u001b[0m | \u001b[0m 7.46    \u001b[0m | \u001b[0m 1.189   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-91.62   \u001b[0m | \u001b[0m 6.059   \u001b[0m | \u001b[0m 0.1491  \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m-92.55   \u001b[0m | \u001b[0m 9.077   \u001b[0m | \u001b[0m 0.4737  \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m-92.22   \u001b[0m | \u001b[0m 9.86    \u001b[0m | \u001b[0m 0.3135  \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m-91.72   \u001b[0m | \u001b[0m 8.569   \u001b[0m | \u001b[0m 0.1997  \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m-90.86   \u001b[0m | \u001b[0m 9.979   \u001b[0m | \u001b[0m 0.1417  \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m-90.97   \u001b[0m | \u001b[0m 7.086   \u001b[0m | \u001b[0m 0.1171  \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m-91.07   \u001b[0m | \u001b[0m 9.685   \u001b[0m | \u001b[0m 0.153   \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m-89.95   \u001b[0m | \u001b[0m 9.967   \u001b[0m | \u001b[0m 0.102   \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m-90.57   \u001b[0m | \u001b[0m 8.495   \u001b[0m | \u001b[0m 0.1177  \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m-91.49   \u001b[0m | \u001b[0m 6.97    \u001b[0m | \u001b[0m 0.1452  \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m-92.66   \u001b[0m | \u001b[0m 9.616   \u001b[0m | \u001b[0m 8.125   \u001b[0m |\n",
      "=================================================\n",
      "{'target': -89.89462701210142, 'params': {'C': 10.0, 'gamma': 0.1}}\n"
     ]
    }
   ],
   "source": [
    "def svr_cv(C, gamma):\n",
    "    res =cross_val_score(\n",
    "        SVR(C = float(C),\n",
    "            gamma = float(gamma),\n",
    "            kernel = 'rbf'),\n",
    "        X, y, scoring='neg_mean_squared_error', cv=10\n",
    "    ).mean()\n",
    "    return res\n",
    "\n",
    "svr_op = BayesianOptimization(\n",
    "        svr_cv,\n",
    "        {'C': (0.1, 10.0),\n",
    "        'gamma':  (0.1, 10.0)}\n",
    "    )\n",
    "\n",
    "svr_op.maximize()\n",
    "print(svr_op.max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 其他方法\n",
    "其他的启发式算法好像没发在这个问题上使用，没有找到合适的例子。。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "289.275px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
